{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Hello, TPU in Colab",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/TheDraguun/collabtf2.0/blob/master/TPU_in_Colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "_pQCOmISAQBu"
      },
      "cell_type": "markdown",
      "source": [
        "# Testing out the TPU connection\n",
        "\n",
        "First, you'll need to enable TPUs for the notebook.\n",
        "\n",
        "Navigate to Edit→Notebook Settings, and select TPU from the Hardware Accelerator drop-down (you can also access Notebook Settings via the command palette: cmd/ctrl-shift-P).\n",
        "\n",
        "Next, we'll check that we can connect to the TPU."
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "71iSWtsXe36x",
        "outputId": "af8af1ca-bf2c-4120-826c-d7c27f565905",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 887
        }
      },
      "cell_type": "code",
      "source": [
        "!pip show tensorflow\n",
        "\n",
        "!pip install tensorflow==1.12\n",
        "\n",
        "!pip show tensorflow\n",
        "\n",
        "import os\n",
        "import pprint\n",
        "import tensorflow as tf\n",
        "\n",
        "if 'COLAB_TPU_ADDR' not in os.environ:\n",
        "  print('ERROR: Not connected to a TPU runtime; please see the first cell in this notebook for instructions!')\n",
        "else:\n",
        "  tpu_address = 'grpc://' + os.environ['COLAB_TPU_ADDR']\n",
        "  print ('TPU address is', tpu_address)\n",
        "\n",
        "  with tf.Session(tpu_address) as session:\n",
        "    devices = session.list_devices()\n",
        "    \n",
        "  print('TPU devices:')\n",
        "  pprint.pprint(devices)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Name: tensorflow\n",
            "Version: 1.12.0\n",
            "Summary: TensorFlow is an open source machine learning framework for everyone.\n",
            "Home-page: https://www.tensorflow.org/\n",
            "Author: Google Inc.\n",
            "Author-email: opensource@google.com\n",
            "License: Apache 2.0\n",
            "Location: /usr/local/lib/python3.6/dist-packages\n",
            "Requires: astor, termcolor, keras-preprocessing, keras-applications, six, numpy, tensorboard, protobuf, gast, absl-py, grpcio, wheel\n",
            "Required-by: stable-baselines, magenta, fancyimpute\n",
            "Requirement already satisfied: tensorflow==1.12 in /usr/local/lib/python3.6/dist-packages (1.12.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.12) (1.1.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.12) (1.0.9)\n",
            "Requirement already satisfied: absl-py>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.12) (0.7.0)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.12) (3.6.1)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.12) (0.33.1)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.12) (1.15.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.12) (1.11.0)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.12) (0.7.1)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.12) (1.0.7)\n",
            "Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.12) (0.2.2)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.12) (1.14.6)\n",
            "Requirement already satisfied: tensorboard<1.13.0,>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.12) (1.12.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.1->tensorflow==1.12) (40.8.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.6->tensorflow==1.12) (2.8.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.13.0,>=1.12.0->tensorflow==1.12) (3.0.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.10 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.13.0,>=1.12.0->tensorflow==1.12) (0.14.1)\n",
            "Name: tensorflow\n",
            "Version: 1.12.0\n",
            "Summary: TensorFlow is an open source machine learning framework for everyone.\n",
            "Home-page: https://www.tensorflow.org/\n",
            "Author: Google Inc.\n",
            "Author-email: opensource@google.com\n",
            "License: Apache 2.0\n",
            "Location: /usr/local/lib/python3.6/dist-packages\n",
            "Requires: protobuf, numpy, grpcio, absl-py, wheel, astor, six, termcolor, tensorboard, gast, keras-applications, keras-preprocessing\n",
            "Required-by: stable-baselines, magenta, fancyimpute\n",
            "TPU address is grpc://10.125.99.186:8470\n",
            "TPU devices:\n",
            "[_DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:CPU:0, CPU, -1, 16926298337797062392),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 17179869184, 6367200962100316058),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:0, TPU, 17179869184, 15851637458224776926),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:1, TPU, 17179869184, 4168699861103805315),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:2, TPU, 17179869184, 8812976313523324037),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:3, TPU, 17179869184, 12255072959079337047),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:4, TPU, 17179869184, 139329390795983028),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:5, TPU, 17179869184, 10675670025516012719),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:6, TPU, 17179869184, 9303743485078740459),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:7, TPU, 17179869184, 11916760721252329292),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 17179869184, 14262749569439253453)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "Jkh7cEWRAEA-"
      },
      "cell_type": "markdown",
      "source": [
        "If the cell above reports an error, make sure that you have enabled TPU support in the notebook settings. (Edit menu → Notebook settings)\n",
        "\n",
        "Now, let's try a simple computation."
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "0iqSZvc6AX1m",
        "outputId": "0979caf2-8416-433d-bcfc-1868a8ee8284",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "cell_type": "code",
      "source": [
        "\n",
        "import numpy as np\n",
        "\n",
        "def add_op(x, y):\n",
        "  return x + y\n",
        "  \n",
        "x = tf.placeholder(tf.float32, [10,])\n",
        "y = tf.placeholder(tf.float32, [10,])\n",
        "tpu_ops = tf.contrib.tpu.rewrite(add_op, [x, y])\n",
        "  \n",
        "session = tf.Session(tpu_address)\n",
        "try:\n",
        "  print('Initializing...')\n",
        "  session.run(tf.contrib.tpu.initialize_system())\n",
        "  print('Running ops')\n",
        "  print(session.run(tpu_ops, {x: np.arange(10), y: np.arange(10)}))\n",
        "finally:\n",
        "  # For now, TPU sessions must be shutdown separately from\n",
        "  # closing the session.\n",
        "  session.run(tf.contrib.tpu.shutdown_system())\n",
        "  session.close()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Initializing...\n",
            "Running ops\n",
            "[array([ 0.,  2.,  4.,  6.,  8., 10., 12., 14., 16., 18.], dtype=float32)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "nhXwaCNWBK2n"
      },
      "cell_type": "markdown",
      "source": [
        "# TPU FLOPs\n",
        "\n",
        "Finally, we'll try a small test of floating point computations (floating point operations per seconds. (The units are FLOPS: floating point operations per second.)"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "llcFb_P_BNPM",
        "outputId": "296b9970-bb23-4f40-8720-be3233c07605",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "cell_type": "code",
      "source": [
        "N = 4096\n",
        "COUNT = 100\n",
        "import time\n",
        "\n",
        "def flops():\n",
        "  x = tf.random_uniform([N, N])\n",
        "  y = tf.random_uniform([N, N])\n",
        "  def _matmul(x, y):\n",
        "    return tf.tensordot(x, y, axes=[[1], [0]]), y\n",
        "\n",
        "  return tf.reduce_sum(\n",
        "    tf.contrib.tpu.repeat(COUNT, _matmul, [x, y])\n",
        "  )\n",
        "  \n",
        "tpu_ops = tf.contrib.tpu.batch_parallel(flops, [], num_shards=8)\n",
        "  \n",
        "session = tf.Session(tpu_address)\n",
        "try:\n",
        "  print('Warming up...')\n",
        "  session.run(tf.contrib.tpu.initialize_system())\n",
        "  session.run(tpu_ops)\n",
        "  print('Profiling')\n",
        "  start = time.time()\n",
        "  session.run(tpu_ops)\n",
        "  end = time.time()\n",
        "  elapsed = end - start\n",
        "  print(elapsed, 'TFlops: {:.2f}'.format(1e-12 * 8 * COUNT * 2*N*N*N / elapsed))\n",
        "finally:\n",
        "  session.run(tf.contrib.tpu.shutdown_system())\n",
        "  session.close()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Warming up...\n",
            "Profiling\n",
            "0.674267053604126 TFlops: 163.07\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "a_rjVo-RAoYd"
      },
      "cell_type": "markdown",
      "source": [
        "# Next steps\n",
        "\n",
        "More involved examples include:\n",
        "- [Shakespeare in 5 minutes with Cloud TPUs and Keras](https://colab.research.google.com/github/tensorflow/tpu/blob/master/tools/colab/shakespeare_with_tpu_and_keras.ipynb)\n",
        "- [Shakespeare in 5 minutes with Cloud TPUs via TPUEstimator](https://colab.research.google.com/github/tensorflow/tpu/blob/master/tools/colab/shakespeare_with_tpuestimator.ipynb)\n",
        "- [Fashion MNIST with Keras and TPUs](https://colab.research.google.com/github/tensorflow/tpu/blob/master/tools/colab/fashion_mnist.ipynb)\n",
        "\n",
        "We'll be sharing more examples of TPU use in Colab over time, so be sure to check back for additional example links, or [follow us on Twitter @GoogleColab](https://twitter.com/googlecolab).\n",
        "\n",
        "Meanwhile, you can check out the [TPUEstimator documentation on TensorFlow.org](https://www.tensorflow.org/api_docs/python/tf/contrib/tpu/TPUEstimator). TPUEstimator is an easy way to update models to take advantage of TPU acceleration."
      ]
    }
  ]
}